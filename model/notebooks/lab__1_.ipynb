{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import device, cuda, no_grad, optim, max\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition & Preprocessing\n",
    "- Load the dataset\n",
    "- Prepare labels\n",
    "- Prepare data\n",
    "- Create loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>common_voice_fr_22098482.wav</td>\n",
       "      <td>trois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>common_voice_fr_21955578.wav</td>\n",
       "      <td>quatre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>common_voice_fr_22500710.wav</td>\n",
       "      <td>un</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>common_voice_fr_21964070.wav</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>common_voice_fr_22357111.wav</td>\n",
       "      <td>trois</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           path sentence\n",
       "0  common_voice_fr_22098482.wav    trois\n",
       "1  common_voice_fr_21955578.wav   quatre\n",
       "2  common_voice_fr_22500710.wav       un\n",
       "3  common_voice_fr_21964070.wav      non\n",
       "4  common_voice_fr_22357111.wav    trois"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>common_voice_fr_22098482.wav</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>common_voice_fr_21955578.wav</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>common_voice_fr_22500710.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>common_voice_fr_21964070.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>common_voice_fr_22357111.wav</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           path  sentence\n",
       "0  common_voice_fr_22098482.wav         4\n",
       "1  common_voice_fr_21955578.wav         5\n",
       "2  common_voice_fr_22500710.wav         2\n",
       "3  common_voice_fr_21964070.wav         1\n",
       "4  common_voice_fr_22357111.wav         4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = {'oui': 0, 'non': 1, 'un': 2, 'deux': 3, 'trois': 4, 'quatre': 5}\n",
    "df['sentence'] = df['sentence'].map(sentence)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sample Rate : 44100, 22050, 16000\n",
    "* Taille de la fenêtre de transformation de Fourier : n_fft\n",
    "* Décalage : hop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_spectrogram(audio_file, sample_rate=22050, n_fft=2048, hop_length=512):\n",
    "    y, sr = librosa.load(audio_file, sr=sample_rate)\n",
    "    spectrogram = np.abs(librosa.stft(y, n_fft=n_fft, hop_length=hop_length))\n",
    "    return spectrogram\n",
    "\n",
    "\n",
    "df['path'] = df['path'].apply(lambda x: 'data/clips/' + x)\n",
    "df['spectrogram'] = df['path'].apply(lambda x: audio_to_spectrogram(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_x = 0\n",
    "max_y = 0\n",
    "\n",
    "for spectrogram in df['spectrogram']:\n",
    "    if spectrogram.shape[0] > max_x:\n",
    "        max_x = spectrogram.shape[0]\n",
    "    if spectrogram.shape[1] > max_y:\n",
    "        max_y = spectrogram.shape[1]\n",
    "\n",
    "df['spectrogram'] = df['spectrogram'].apply(lambda x: np.resize(x, (max_x, max_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['spectrogram'] = df['spectrogram'].apply(lambda x: torch.tensor(x))\n",
    "df['sentence'] = df['sentence'].apply(lambda x: torch.tensor(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.dataframe.iloc[idx]['sentence']\n",
    "        data = self.dataframe.iloc[idx]['spectrogram']\n",
    "        return label, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement : 6921\n",
      "Taille de l'ensemble de test : 1731\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, train_size=0.8, random_state=42)\n",
    "\n",
    "print(\"Taille de l'ensemble d'entraînement :\", len(train_df))\n",
    "print(\"Taille de l'ensemble de test :\", len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = CustomDataset(train_df)\n",
    "test_df = CustomDataset(test_df)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "loaders = {\n",
    "    \"train\" : DataLoader(train_df, batch_size=batch_size, shuffle=True, num_workers=16),\n",
    "    \"test\" : DataLoader(test_df, batch_size=batch_size, num_workers=16)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "* CNN\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 256 * 116, 128)\n",
    "        self.fc2 = nn.Linear(128, 6)\n",
    "        self.dropout = nn.Dropout(0.5) # to avoid overfitting\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 256 * 116)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        #x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [1:06:14<00:00, 18.31s/it]\n",
      "100%|██████████| 55/55 [03:59<00:00,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Loss: 1335.55140042305, Train Accuracy: 0.2031498338390406, Test Accuracy: 0.25014442518775276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "accuracies = []\n",
    "losses = []\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for labels, inputs in tqdm(loaders['train']):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.unsqueeze(1).float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        total += labels.size(0)\n",
    "    losses.append(loss/total)\n",
    "    accuracies.append(evaluate(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for labels, inputs in tqdm(loaders['test']):\n",
    "        outputs = model(inputs.unsqueeze(1).float())\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "test_accuracy = correct / total\n",
    "\n",
    "print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss}, Train Accuracy: {train_accuracy}, Test Accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    model.eval\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for labels, inputs in tqdm(loaders['test']):\n",
    "            outputs = model(inputs.unsqueeze(1).float())\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
