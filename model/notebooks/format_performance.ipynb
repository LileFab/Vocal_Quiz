{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import subprocess \n",
    "import os\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/validated.tsv', delimiter='\\t')\n",
    "df = df[df['sentence'].str.contains(r'un|deux|trois|quatre|oui|non')]\n",
    "\n",
    "for index, row in df.iterrows(): # keep only files which contain the words we are interested in\n",
    "    shutil.copy(\"../../data/all_clips/\" + row['path'], \"../../data/clips/\" + row['path'])\n",
    "\n",
    "df[\"path\"] = df[\"path\"].str.replace(\".mp3\", \".wav\")\n",
    "df = df.drop(columns=['client_id', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'])\n",
    "df.to_csv('../../data/data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../../data/clips'\n",
    "wav_directory = '../../data/clips_wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    if os.path.isfile(f):\n",
    "        input_file = f\n",
    "        output_file = os.path.join('../../data/clips_wav', filename.replace(\".mp3\", \".wav\"))\n",
    "        subprocess.call(['ffmpeg', '-v', '0' , '-y', '-i', input_file, output_file])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mp3 files: 10767\n",
      "wav files: 8652\n"
     ]
    }
   ],
   "source": [
    "print(f'mp3 files: {len(os.listdir(directory))}')\n",
    "\n",
    "print(f'wav files: {len(os.listdir(wav_directory))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_power_spectrogram(audio_file, sample_rate=22050, n_fft=2048, hop_length=512):\n",
    "    y, sr = librosa.load(audio_file, sr=sample_rate)\n",
    "    spectrogram = np.abs(librosa.stft(y, n_fft=n_fft, hop_length=hop_length)) ** 2\n",
    "    return spectrogram, y\n",
    "\n",
    "def audio_to_mel_spectrogram_db(audio_file, sample_rate=22050, n_fft=2048, hop_length=512):\n",
    "    spectrogram, y = audio_to_power_spectrogram(audio_file, sample_rate, n_fft, hop_length)\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sample_rate, S=spectrogram, n_fft=n_fft, hop_length=hop_length, win_length=n_fft)\n",
    "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max) \n",
    "    return mel_spectrogram_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257, 123)\n"
     ]
    }
   ],
   "source": [
    "file = '../../data/clips_wav/common_voice_fr_21894154.wav'\n",
    "spectre = audio_to_power_spectrogram(file, sample_rate=22020, n_fft=512, hop_length=512)[0]\n",
    "print(spectre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>common_voice_fr_22098482.wav</td>\n",
       "      <td>trois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>common_voice_fr_21955578.wav</td>\n",
       "      <td>quatre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>common_voice_fr_22500710.wav</td>\n",
       "      <td>un</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>common_voice_fr_21964070.wav</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>common_voice_fr_22357111.wav</td>\n",
       "      <td>trois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>common_voice_fr_22591161.wav</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           path sentence\n",
       "0  common_voice_fr_22098482.wav    trois\n",
       "1  common_voice_fr_21955578.wav   quatre\n",
       "2  common_voice_fr_22500710.wav       un\n",
       "3  common_voice_fr_21964070.wav      non\n",
       "4  common_voice_fr_22357111.wav    trois\n",
       "5  common_voice_fr_22591161.wav      oui"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/data.csv', delimiter=',')\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate=22050\n",
    "hop_length = 512 # in num. of samples\n",
    "n_fft = 512 # window in num. of samples\n",
    "\n",
    "df = pd.read_csv('../../data/data.csv')\n",
    "df['path_wav'] = df['path'].apply(lambda x: '../../data/clips_wav/' + x)\n",
    "df['path_mp3'] = df['path'].apply(lambda x: '../../data/clips/' + x.replace(\".wav\", \".mp3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(spectrograms):\n",
    "    max_x = 0\n",
    "    max_y = 0\n",
    "\n",
    "    for spectrogram in spectrograms:\n",
    "        if spectrogram.shape[0] > max_x:\n",
    "            max_x = spectrogram.shape[0]\n",
    "        if spectrogram.shape[1] > max_y:\n",
    "            max_y = spectrogram.shape[1]\n",
    "\n",
    "    print('max shape 0 size : ', max_x)\n",
    "    print('max shape 1 size : ', max_y)\n",
    "    \n",
    "    result = [F.pad(input=spectrogram, pad=(0, max_y - spectrogram.shape[1], 0, max_x - spectrogram.shape[0]), mode='constant', value=0) for spectrogram in spectrograms]\n",
    "    \n",
    "    # taille_tensor = len(spectrograms)\n",
    "    # batch_size = 500\n",
    "    # nb_batch = math.ceil(taille_tensor / batch_size)\n",
    "    # i = 0\n",
    "    # j = batch_size\n",
    "    \n",
    "    # for b in range(nb_batch):\n",
    "    #     batch = spectrograms[i:j]\n",
    "        \n",
    "        # for spectrogram in batch:\n",
    "            # result.append(F.pad(input=spectrogram, pad=(0, max_y - spectrogram.shape[1], 0, max_x - spectrogram.shape[0]), mode='constant', value=0))\n",
    "            \n",
    "\n",
    "        # spectrograms = spectrograms[j:]\n",
    "        # print('audio to pad left : ', len(spectrograms))\n",
    "    \n",
    "    del spectrograms\n",
    "    return result\n",
    "\n",
    "def spectrogram_to_tensor_save(spectrogram, filename):\n",
    "    spectrogram = [torch.tensor(data, dtype=torch.float16) for data in spectrogram]\n",
    "    spectrogram = pad(spectrogram)\n",
    "    spectrogram = torch.stack(spectrogram)\n",
    "    torch.save(spectrogram, f'../../data/{filename}.pt')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav to spectrogram : 53.9186429977417 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "spectrogram_wav = df['path_wav'].apply(lambda x: audio_to_power_spectrogram(x)[0])\n",
    "spectrogram_wav_time = time.time() - start_time\n",
    "\n",
    "print(f'wav to spectrogram : {spectrogram_wav_time} seconds')\n",
    "\n",
    "# spectrogram_to_tensor_save(spectrogram_wav, 'spectrogram_wav')\n",
    "\n",
    "\n",
    "# clear variable for RAM space\n",
    "del spectrogram_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav to mel spectrogram : 86.52624773979187 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "mel_spectrogram_wav = df['path_wav'].apply(lambda x: audio_to_mel_spectrogram_db(x))\n",
    "mel_spectrogram_wav_time = time.time() - start_time\n",
    "\n",
    "print(f'wav to mel spectrogram : {mel_spectrogram_wav_time} seconds')\n",
    "\n",
    "# spectrogram_to_tensor_save(mel_spectrogram_wav, 'mel_spectrogram_wav')\n",
    "\n",
    "\n",
    "# clear variable for RAM space\n",
    "del mel_spectrogram_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mp3 to spectrogram : 68.04297113418579 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "spectrogram_mp3 = df['path_mp3'].apply(lambda x: audio_to_power_spectrogram(x)[0])\n",
    "spectrogram_mp3_time = time.time() - start_time\n",
    "\n",
    "print(f'mp3 to spectrogram : {spectrogram_mp3_time} seconds')\n",
    "\n",
    "# spectrogram_to_tensor_save(spectrogram_mp3, 'spectrogram_mp3')\n",
    "\n",
    "\n",
    "# clear variable for RAM space\n",
    "del spectrogram_mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mp3 to mel spectrogram : 101.2370855808258 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "mel_spectrogram_mp3 = df['path_mp3'].apply(lambda x: audio_to_mel_spectrogram_db(x))\n",
    "mel_spectrogram_mp3_time = time.time() - start_time\n",
    "\n",
    "print(f'mp3 to mel spectrogram : {mel_spectrogram_mp3_time} seconds')\n",
    "\n",
    "# spectrogram_to_tensor_save(mel_spectrogram_mp3, 'mel_spectrogram_mp3')\n",
    "\n",
    "\n",
    "# clear variable for RAM space\n",
    "del mel_spectrogram_mp3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
